# -*- coding: utf-8 -*-
"""AdvanceML_EX1 _Part2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1equOe_nUaKrt0PCGt5CFfoGX1fXwC1H9
"""

import math
import torch
from torch import nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Set device to cuda if possible
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
SEED = 42
NUMBER_OF_PIXELS = 784
LATENT_DIM = 200
BATCH_SIZE = 64
POSTERIOR_STD = 0.4
NUM_OF_EPOCH = 30
DECODER_LR = 1e-3
LATENT_LR = 1e-2

# Set Random Seed
torch.manual_seed(SEED)          # Sets the seed for CPU
torch.cuda.manual_seed(SEED)     # Sets the seed for the current GPU

# Load MNIST dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
# take a stratified subset of the training data, keeping only 5000 samples, with 500 samples per class
train_targets = train_dataset.targets
train_idx, _ = train_test_split(range(len(train_targets)), train_size=20000, stratify=train_targets)
train_dataset = torch.utils.data.Subset(train_dataset, train_idx)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

"""**Auxiliary functions**"""

def sample_indices_and_images(dataloader, batch_size, num_of_samples_per_digit):
    digit_keys = {i:num_of_samples_per_digit for i in range(10)}
    digit_indices = {i:[] for i in range(10)}
    digit_images = {i:[] for i in range(10)}

    for index, (images, labels) in enumerate(tqdm(dataloader)):
        for i in range(labels.size()[0]):
            digit = labels[i].item()
            if digit in digit_keys:
                digit_indices[digit].append(index * batch_size + i)
                digit_images[digit].append(images[i])
                digit_keys[digit] -= 1
                if digit_keys[digit] == 0:
                  del digit_keys[digit]

            if len(digit_keys.keys()) == 0:
                break

    if len(digit_keys.keys()) != 0:
        print(f'Error: The digits {digit_keys.keys()} has not enough assosiated samples in the given dataloader dataset')
        return None

    return digit_indices, digit_images

    # Convert lists to tensors
    res_indices = torch.tensor(res_indices)
    res_images = torch.stack(res_images, dim=0)

    # Move tensors to DEVICE
    res_indices = res_indices.to(DEVICE)
    res_images = res_images.to(DEVICE)

    return res_indices, res_images

def plot_vae_losses(val_losses):
    plot = make_subplots(rows=1, cols=1, subplot_titles=('Validation losses as functions of number of epoch'))

    x = epochs = torch.arange(1, len(val_losses) + 1, 1)

    plot.update_xaxes(title_text="Epochs Number", row=1, col=1)
    plot.update_yaxes(title_text="Avarage Loss", row=1, col=1)
    plot.add_trace(
    go.Scatter(x=epochs, y=val_losses, mode='lines+markers', name='Average validation loss',
               marker=dict(color='#0000FF', size=10)), row=1, col=1)

    plot.show()

def present_rec_images(real_images, rec_images_list, chosen_epochs_list):
    num_rows = len(rec_images_list) + 1
    num_cols = len(rec_images_list[0])

    # Create a figure
    fig = plt.figure(constrained_layout=True, figsize=(10, num_rows * 1.25))
    fig.suptitle('Real images vs Reconstructed images after each epoch')
    plt.subplots_adjust(top=1, bottom=1)

    # Create subfigures
    subfigs = fig.subfigures(nrows=num_rows, ncols=1)
    for row, subfig in enumerate(subfigs):
        # Set subtitle for each row
        if row == 0:
            subfig.suptitle('Real images')
        else:
            subfig.suptitle(f'Reconstructed images after {chosen_epochs_list[row - 1]} epochs')

        # Create subplots within each subfigure
        axs = subfig.subplots(nrows=1, ncols=num_cols)
        for col, ax in enumerate(axs):
            ax.axis('off')
            ax.set_title(f'Digit {col}')
            if row == 0:
                ax.imshow(real_images[col].squeeze().to('cpu'), cmap='gray')
            else:
                ax.imshow(rec_images_list[row - 1][col].squeeze().to('cpu'), cmap='gray')

    plt.show()

def present_gen_images(gen_images_list, chosen_epochs_list):
    num_rows = len(gen_images_list)
    num_cols = len(gen_images_list[0])

    # Create a figure
    fig = plt.figure(constrained_layout=True, figsize=(10, num_rows * 1.25))
    fig.suptitle('Generated images from latent variables after each epoch')
    plt.subplots_adjust(top=1, bottom=1)

    # Create subfigures
    subfigs = fig.subfigures(nrows=num_rows, ncols=1)
    for row, subfig in enumerate(subfigs):
        # Set subtitle for each row
        subfig.suptitle(f'Generated images from latent variables after {chosen_epochs_list[row]} epochs')

        # Create subplots within each subfigure
        axs = subfig.subplots(nrows=1, ncols=num_cols)
        for col, ax in enumerate(axs):
            ax.axis('off')
            ax.imshow(gen_images_list[row][col].squeeze().to('cpu'), cmap='gray')

    plt.show()

def compute_gaussian_log_probs(samples_tensor, mean_tensor, var_tensor):
    tensor1 = torch.log(2 * torch.pi * var_tensor)
    tensor2 = torch.pow(samples_tensor - mean_tensor, 2) / var_tensor
    log_probs_vector = -0.5 * torch.sum(tensor1 + tensor2, dim=1)

    return log_probs_vector

def present_images_with_log_probs(images, log_probs):
    num_cols = images.size()[0]

    # Create a figure
    fig, axs = plt.subplots(nrows=1, ncols=num_cols, figsize=(20, 2))
    for i in range(10):
        axs[i].imshow(images[i].squeeze().to('cpu'), cmap='gray')
        axs[i].set_title(f'Log Prob: {log_probs[i]:.2f}')
        axs[i].axis('off')

    plt.show()

"""**Questions 1 + 2**"""

# ConvAmortizedVAE class
class ConvAmortizedVAE(nn.Module):
    def __init__(self, latent_dim=LATENT_DIM):
        super(ConvAmortizedVAE, self).__init__()

        self.latent_dim = latent_dim

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # (batch_size, 32, 14, 14)
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # (batch_size, 64, 7, 7)
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (batch_size, 128, 4, 4)
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=2)  # (batch_size, 128, 1, 1)
        )

        # Latent space
        self.fc_mu = nn.Linear(128, latent_dim)
        self.fc_logvar = nn.Linear(128, latent_dim)
        self.fc_decode = nn.Linear(latent_dim, 128)

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 128, kernel_size=2),  # (batch_size, 128, 2, 2)
            nn.ReLU(),
            nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch_size, 128, 4, 4)
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1),  # (batch_size, 64, 7, 7)
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch_size, 32, 14, 14)
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch_size, 1, 28, 28)
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + std * eps


    def encode(self, x):
        x = self.encoder(x)
        # add average pooling
        x = F.adaptive_avg_pool2d(x, 1)
        x = x.view(x.size(0), -1)  # Flatten
        mu = self.fc_mu(x)
        logvar = self.fc_logvar(x)
        return mu, logvar

    def decode(self, z):
        z = self.fc_decode(z)
        z = z.view(z.size(0), 128, 1, 1)
        z = self.decoder(z)
        return z

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)
        return recon_x, mu, logvar

def train_amortized_VAE(num_epochs=NUM_OF_EPOCH, random_val_images=None, random_train_images=None, latent_variables=None, chosen_epochs=[]):
    vae_model = ConvAmortizedVAE()
    vae_model = vae_model.to(DEVICE)
    optimizer = optim.Adam(vae_model.parameters(), lr=DECODER_LR)

    train_mean_losses = []
    rec_val_images_list = []
    rec_train_images_list = []
    gen_latent_images_list = []
    for epoch in range(1, num_epochs + 1):
        vae_model.train()
        epoch_train_mean_loss = 0.0
        epoch_train_weight = 0

        for images, _ in tqdm(train_loader):
            # Move images to DEVICE
            images = images.to(DEVICE)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward stage
            rec_images, pred_mu, pred_logvar = vae_model(images)

            # Calculate VAE loss
            mse_loss = (torch.sum((images - rec_images).pow(2), dim=[1,2,3])).mean()
            kl_loss = (0.5 * torch.sum(torch.exp(pred_logvar) + pred_mu.pow(2) - pred_logvar - 1, dim=1)).mean()
            vae_loss = mse_loss + kl_loss


            # Backpropagate and update the vae_model's wight
            vae_loss.backward()
            optimizer.step()

            # Update loss variable for this epoch
            batch_num_of_samples = images.size()[0]
            epoch_train_mean_loss = (epoch_train_weight * epoch_train_mean_loss + batch_num_of_samples * vae_loss.item()) / (epoch_train_weight + batch_num_of_samples)
            epoch_train_weight += batch_num_of_samples

        # Add epoch avarage loss to list
        train_mean_losses.append(epoch_train_mean_loss)

        if epoch in chosen_epochs:
          vae_model.eval()
          with torch.no_grad():
            # Reconstruct random validaion images
            if random_val_images is not None:
              rec_val_images, _, _ = vae_model(random_val_images)
              rec_val_images_list.append(rec_val_images)

            # Reconstruct random training images
            if random_train_images is not None:
              rec_train_images, _, _ = vae_model(random_train_images)
              rec_train_images_list.append(rec_train_images)

            # Generate images from latent variables
            if latent_variables is not None:
              gen_latent_images = vae_model.decode(latent_variables)
              gen_latent_images_list.append(gen_latent_images)

    return vae_model, train_mean_losses, rec_val_images_list, rec_train_images_list, gen_latent_images_list

chosen_epochs = [1, 5, 10, 20, 30]
# Sample 10 random latent vectors from standart gaussian distribution
latent_variables = torch.randn(10, LATENT_DIM).to(DEVICE)
# Create a new train and validation dataloader
new_val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)
new_train_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)
# Choose 10 random images from validation and training dataset
val_ret_tuple = sample_indices_and_images(dataloader=new_val_loader, batch_size=BATCH_SIZE, num_of_samples_per_digit=1)
train_ret_tuple = sample_indices_and_images(dataloader=new_train_loader, batch_size=BATCH_SIZE, num_of_samples_per_digit=1)
if val_ret_tuple is not None and train_ret_tuple is not None:
    # Create a tensor of the selected images
    _, val_digit_images = val_ret_tuple
    _, train_digit_images = train_ret_tuple

    val_selected_images = [val_digit_images[digit][0] for digit in range(10)]
    val_selected_images = torch.stack(val_selected_images, dim=0).to(DEVICE)

    train_selected_images = [train_digit_images[digit][0] for digit in range(10)]
    train_selected_images = torch.stack(train_selected_images, dim=0).to(DEVICE)

    # Train the Amortized VAE model
    amortized_vae_model, train_mean_losses, rec_val_images_list, rec_train_images_list, gen_latent_images_list = train_amortized_VAE(
        random_val_images=val_selected_images, random_train_images=train_selected_images, latent_variables=latent_variables, chosen_epochs=chosen_epochs)

    # Plot avarage train loss on each epoch
    print("\nPlot of avarage train loss:")
    plot_vae_losses(train_mean_losses)

    # Present validation reconstructed images during the training on chosen epochs
    print("\nValidation reconstructed images:")
    present_rec_images(val_selected_images, rec_val_images_list, chosen_epochs)

    # Present training reconstructed images during the training on chosen epochs
    print("\nTraining reconstructed images:")
    present_rec_images(train_selected_images, rec_train_images_list, chosen_epochs)

    # Present generated images from latent variables during the training on chosen epochs
    print("\nGenerated images from latent variables:")
    present_gen_images(gen_latent_images_list, chosen_epochs)

"""**Question 3**"""

# ConvLatentVAE class
class ConvLatentVAE(nn.Module):
    def __init__(self, num_samples, latent_dim=LATENT_DIM):
        super(ConvLatentVAE, self).__init__()
        self.latent_dim = latent_dim

        # Embadding layer
        self.mean = nn.Parameter(torch.randn(num_samples, latent_dim))
        self.logvar = nn.Parameter(torch.randn(num_samples, latent_dim).pow(2).log())

        # Latent space
        self.fc_decode = nn.Linear(latent_dim, 128)

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 128, kernel_size=2),  # (batch_size, 128, 2, 2)
            nn.ReLU(),
            nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch_size, 128, 4, 4)
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1),  # (batch_size, 64, 7, 7)
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch_size, 32, 14, 14)
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch_size, 1, 28, 28)
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + std * eps

    def decode(self, z):
        z = self.fc_decode(z)
        z = z.view(z.size(0), 128, 1, 1)
        z = self.decoder(z)
        return z

    def forward(self, indices):
        mu, logvar = self.mean[indices], self.logvar[indices]
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)
        return recon_x, mu, logvar

def train_latent_VAE(num_epochs=NUM_OF_EPOCH, data_loader=None, train_selected_indices=None, latent_variables=None, chosen_epochs=[]):
    assert(data_loader is not None)
    vae_model = ConvLatentVAE(num_samples=len(train_dataset))
    vae_model = vae_model.to(DEVICE)
    decoder_optimizer = optim.Adam(vae_model.decoder.parameters(), lr=DECODER_LR)
    latent_optimizer = optim.Adam([vae_model.mean, vae_model.logvar], lr=LATENT_LR)

    train_mean_losses = []
    rec_train_images_list = []
    gen_latent_images_list = []

    for epoch in range(1, num_epochs + 1):
        vae_model.train()
        epoch_train_mean_loss = 0.0
        epoch_num_of_seen_samples = 0

        for images, _ in tqdm(data_loader):
            # Create an indices tensor to assosiate the batch samples with their mean and variant vectors of the embbading layer
            batch_num_of_samples = images.size()[0]
            indices = torch.arange(epoch_num_of_seen_samples, epoch_num_of_seen_samples + batch_num_of_samples).to(DEVICE)

            # Move images to DEVICE
            images = images.to(DEVICE)

            # Zero the parameter gradients
            decoder_optimizer.zero_grad()
            latent_optimizer.zero_grad()

            # Forward stage
            rec_images, pred_mu, pred_logvar = vae_model(indices)

            # Calculate VAE loss
            mse_loss = (torch.sum((images - rec_images).pow(2), dim=[1,2,3])).mean()
            kl_loss = (0.5 * torch.sum(torch.exp(pred_logvar) + pred_mu.pow(2) - pred_logvar - 1, dim=1)).mean()
            vae_loss = mse_loss + kl_loss

            # Backpropagate and update the vae_model's wight
            vae_loss.backward()
            decoder_optimizer.step()
            latent_optimizer.step()

            # Update loss variable for this epoch
            epoch_train_mean_loss = (epoch_num_of_seen_samples * epoch_train_mean_loss + batch_num_of_samples * vae_loss.item()) / (epoch_num_of_seen_samples + batch_num_of_samples)
            epoch_num_of_seen_samples += batch_num_of_samples

        # Add epoch avarage loss to list
        train_mean_losses.append(epoch_train_mean_loss)

        if epoch in chosen_epochs:
          vae_model.eval()
          with torch.no_grad():
            # Reconstruct random validaion images
            if train_selected_indices is not None:
              rec_train_images, _, _ = vae_model(train_selected_indices)
              rec_train_images_list.append(rec_train_images)

            if latent_variables is not None:
              gen_latent_images = vae_model.decode(latent_variables)
              gen_latent_images_list.append(gen_latent_images)

    return vae_model, train_mean_losses, rec_train_images_list, gen_latent_images_list

chosen_epochs = [1, 5, 10, 20, 30]
# Sample 10 random latent vectors from standart gaussian distribution
latent_variables = torch.randn(10, LATENT_DIM).to(DEVICE)
# Create a new train dataloader
new_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)
# Choose 10 images from training dataset
ret_tuple = sample_indices_and_images(dataloader=new_train_loader, batch_size=BATCH_SIZE, num_of_samples_per_digit=1)
if ret_tuple is not None:
    # Create a tensors of the selected images and their indices
    digit_indices, digit_images = ret_tuple
    train_selected_indices = [digit_indices[digit][0] for digit in range(10)]
    train_selected_indices = torch.tensor(train_selected_indices).to(DEVICE)
    train_selected_images = [digit_images[digit][0] for digit in range(10)]
    train_selected_images = torch.stack(train_selected_images, dim=0).to(DEVICE)

    # Train the latent VAE model
    latent_vae_model, train_mean_losses, rec_train_images_list, gen_latent_images_list = train_latent_VAE(data_loader=new_train_loader,
                                                                                                          train_selected_indices=train_selected_indices, latent_variables=latent_variables, chosen_epochs=chosen_epochs)

    print(len(train_mean_losses))
    # Plot avarage train loss on each epoch
    print("\nPlot of avarage train loss:")
    plot_vae_losses(train_mean_losses)

    # Present training reconstructed images during the training on chosen epochs
    print("\nTraining reconstructed images:")
    present_rec_images(train_selected_images, rec_train_images_list, chosen_epochs)

    # Present generated images during the training on chosen epochs
    print("\nGenerated images from latent variables:")
    present_gen_images(gen_latent_images_list, chosen_epochs)

"""**Question 3.4**"""

M = 500
digit_n_samples = 5

amortized_vae_model.eval()
train_ret_tuple = sample_indices_and_images(dataloader=new_train_loader, batch_size=BATCH_SIZE, num_of_samples_per_digit=digit_n_samples)
val_ret_tuple = sample_indices_and_images(dataloader=new_val_loader, batch_size=BATCH_SIZE, num_of_samples_per_digit=digit_n_samples)

if train_ret_tuple is not None and val_ret_tuple is not None:
    _, train_digit_images = train_ret_tuple
    _, val_digit_images = val_ret_tuple

    # Initiation
    train_images_log_probs = torch.zeros((10, digit_n_samples)).to(DEVICE)
    train_images_tensor = torch.zeros((10, digit_n_samples, 1, 28, 28)).to(DEVICE)

    val_images_log_probs = torch.zeros((10, digit_n_samples)).to(DEVICE)
    val_images_tensor = torch.zeros((10, digit_n_samples, 1, 28, 28)).to(DEVICE)

    # Get image for each digit from the validation dataset
    for digit in range(10):
        for image_num in range(digit_n_samples):
            train_images_tensor[digit][image_num] = train_digit_images[digit][image_num].to(DEVICE)
            val_images_tensor[digit][image_num] = val_digit_images[digit][image_num].to(DEVICE)

    # Compute the log-probabilites of each image in the train and valisation tensors
    for index in range(2):
        if index == 0:
            images_vec = train_images_tensor.view(10 * digit_n_samples, 1, 28, 28).to(DEVICE)
        else:
            images_vec = val_images_tensor.view(10 * digit_n_samples, 1, 28, 28).to(DEVICE)

        number_of_images = images_vec.size()[0]

        # Use amortized_vae_model to compute pred_mu and pred_logvar vectors of the q distribution for each image
        pred_mu, pred_logvar = amortized_vae_model.encode(images_vec)

        # Repeat each mu vector M times
        pred_mu_expended = pred_mu.repeat_interleave(M, dim=0)
        # Repeat each var vector M times
        pred_logvar_expended = pred_logvar.repeat_interleave(M, dim=0)

        # Get (number_of_images * M) samples
        q_dist_sampels = amortized_vae_model.reparameterize(pred_mu_expended, pred_logvar_expended)
        # Get the generator images for each sample and unfold them to a vector of size 784
        mean_images = amortized_vae_model.decode(q_dist_sampels).view(number_of_images * M, NUMBER_OF_PIXELS)
        # Repeat each real image M times and unfold it to a vector of size 784
        val_images_expended = images_vec.repeat_interleave(M, dim=0).view(number_of_images * M, NUMBER_OF_PIXELS)

        # Compute gaussian probabilities
        posterior_log_probs = compute_gaussian_log_probs(samples_tensor=val_images_expended, mean_tensor=mean_images,
                                                var_tensor=math.pow(POSTERIOR_STD, 2) * torch.ones(number_of_images * M, NUMBER_OF_PIXELS).to(DEVICE))
        p_log_probs = compute_gaussian_log_probs(samples_tensor=q_dist_sampels, mean_tensor=torch.zeros(number_of_images * M, LATENT_DIM).to(DEVICE),
                                        var_tensor=torch.ones(number_of_images * M, LATENT_DIM).to(DEVICE))
        q_log_probs = compute_gaussian_log_probs(samples_tensor=q_dist_sampels, mean_tensor=pred_mu_expended, var_tensor=torch.exp(pred_logvar_expended))

        # Combine log probabilities as described in the exrecise (Eq.9)
        combined_log_probs = p_log_probs + posterior_log_probs - q_log_probs
        # Reshape the tensor to a size of (number_of_images, number of samples)
        combined_log_probs = combined_log_probs.view(number_of_images, M)

        # Calculate final log pobability for each image
        log_probs = torch.logsumexp(combined_log_probs, 1) - math.log(M)
        if index == 0:
            train_images_log_probs = log_probs.view(10, digit_n_samples)
        else:
            val_images_log_probs = log_probs.view(10, digit_n_samples)

    # Section A - Plot a single image from each digit, with its log-probability.
    # Get the first column of train_images_tensor and train_images_log_probs
    images = train_images_tensor[:,0,:,:,:]
    log_probs = train_images_log_probs[:, 0]
    # Plot the images and their log probabilities
    present_images_with_log_probs(images=images, log_probs=log_probs)

    # Section B - Present the average log-probability per digit
    print("Present the average log-probability per digit:")
    for digit in range(10):
        train_average_digit_log_prob = torch.mean(train_images_log_probs[digit, :]).item()
        val_average_digit_log_prob = torch.mean(val_images_log_probs[digit, :]).item()
        average_digit_log_prob = (train_average_digit_log_prob + val_average_digit_log_prob) / 2
        print(f"Digit: {digit}, Average log-probability: {average_digit_log_prob:.2f}")

    # Section C - Present the average log-probability of the images from the (i) training set (ii) test set
    print("\nPresent the average log-probability of the images from the training set and test set")
    train_average_log_prob = torch.mean(train_images_log_probs).item()
    val_average_log_prob = torch.mean(val_images_log_probs).item()

    print(f"Avarage log-probability if all train images: {train_average_log_prob:.2f}")
    print(f"Avarage log-probability if all val images: {val_average_log_prob:.2f}")